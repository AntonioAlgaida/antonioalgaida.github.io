<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FWQZ310Q01"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-FWQZ310Q01');
    </script>
    <!-- End Google Analytics -->

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Antonio Guillen-Perez | AI Research & Engineering</title>
    <meta name="description" content="Portfolio of Antonio Guillen-Perez, Ph.D. AI Research & Engineering specializing in Reinforcement Learning, Autonomous Systems, Multi-Agent Systems, and Large-Scale Simulation.">
    <link rel="stylesheet" href="css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&family=Montserrat:wght@700&display=swap" rel="stylesheet">

    <link rel="icon" href="assets/favicons/favicon.ico" type="image/x-icon">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="assets/favicons/favicon-16x16.png">
</head>
<body>
    <div class="container">
        <header id="header">
            <div class="profile-intro">
                <img src="assets/images/portrait.jpg" alt="Antonio Guillen-Perez" class="profile-photo">
                <div class="profile-text">
                    <h1>Antonio Guillen-Perez, Ph.D.</h1>
                    <h2>AI Research & Engineering | Reinforcement Learning & Autonomous Systems</h2>
                    <nav class="links">
                        <a href="assets/documents/Resume_AntonioGuillen.pdf" target="_blank">Resume</a>
                        <a href="https://github.com/AntonioAlgaida" target="_blank">GitHub (Personal)</a>
                        <a href="https://github.com/antonio-guillenperez" target="_blank">GitHub (HPE)</a>
                        <a href="https://scholar.google.com/citations?user=BFS6jXwAAAAJ" target="_blank">Scholar</a>
                        <a href="https://www.linkedin.com/in/antonioguillenperez/" target="_blank">LinkedIn</a>
                        <button id="theme-toggle" title="Toggle dark/light mode">🌙</button>

                    </nav>
                </div>
            </div>
        </header>
        <main>
            <section id="news">
                <h2>Recent News & Highlights</h2>
                <ul>
                    <li>
                        <b>[Aug 2025] New Research Stream: Advancing Autonomous Driving AI.</b>
                        <ul>
                            <li>Developed "Efficient Virtuoso," a state-of-the-art latent diffusion Transformer for goal-conditioned trajectory planning, achieving minADE of 0.25 on Waymo Open Motion Dataset. <a href="https://arxiv.org/abs/2509.03658" target="_blank">[Paper]</a> <a href="https://github.com/AntonioAlgaida/DiffusionTrajectoryPlanner" target="_blank">[GitHub]</a></li>
                            <li>Submitted new research on "Mining the Long Tail" for robust Offline RL in AVs to arXiv, demonstrating significant safety improvements via data curation. <a href="https://arxiv.org/abs/2508.18397" target="_blank">[Paper]</a> <a href="https://github.com/AntonioAlgaida/LongTailOfflineRL" target="_blank">[GitHub]</a></li>
                            <li>Submitted new research on "From Imitation to Optimization" for Offline RL in AVs to arXiv, demonstrating 3.2x higher success rates than BC baselines. <a href="https://arxiv.org/abs/2508.07029" target="_blank">[Paper]</a> <a href="https://github.com/AntonioAlgaida/WaymoOfflineRL" target="_blank">[GitHub]</a></li>
                        </ul>
                    </li>
                    <li><b>[Early 2025]</b> Initiated a new research stream at HPE exploring LLM-based agents for dynamic system control.</li>
                    <li><b>[Nov 2024]</b> Our work on Hierarchical RL, GreenDCC, accepted to the <b>AAAI 2025</b> Demonstration Track.</li>
                    <li><b>[Oct 2024]</b> Our MARL benchmark, SustainDC, accepted to the <b>NeurIPS 2024</b> Datasets and Benchmarks Track.</li>
                    <li><b>[May 2024]</b> Filed a new U.S. patent on "Real-Time Carbon Footprint Reduction Controller".</li>
                    <li><b>[Dec 2023]</b> Received the <b>Best ML Innovation Award</b> at the NeurIPS 2023 Climate Change AI Workshop.</li>
                    <li><b>[Sep 2022]</b> Joined <b>HPE AI Labs</b> as an AI Research/Applied Scientist.</li>
                    <li><b>[Jun 2022]</b> Awarded Ph.D. in Computer Science with <a href="https://drive.google.com/file/d/1j-4BvGK5N6DE8vdIdexQrcpIxZ-4L_zG/view" target="_blank"><b>Cum Laude</b></a> distinction.</li>

                </ul>
            </section>
            <section id="about">
                <h2>About Me</h2>
                <p>
                    I am a <b>Ph.D. AI Research Scientist and Engineer</b> focused on creating the intelligent systems and foundational models needed for robust, general-purpose autonomy. My work is built on the following principles:
                </p>
                <ul class="about-highlights">
                    <li>
                        <strong>Scientific Foundation:</strong> My research centers on <b>Reinforcement Learning (RL), Multi-Agent Systems, and Imitation Learning</b> to solve complex coordination and control problems, resulting in novel algorithms like LfOD and publications at venues like NeurIPS and AAAI.
                    </li>
                    <li>
                        <strong>Engineering Execution:</strong> I architect and implement the necessary infrastructure to bring research to life, from <b>large-scale, open-source simulations (SustainDC)</b> to distributed training pipelines (Ray/RLlib) with hundreds of parallel workers.
                    </li>
                    <li>
                        <strong>Future Focus:</strong> My recent work explores the frontier of <b>LLM-based agents</b>, using fine-tuning (LoRA) and novel refinement techniques to build more capable and adaptable decision-makers for real-world systems.
                    </li>
                </ul>
            </section>
            <section id="projects">
                <h2>Featured Projects</h2>

            <!-- NEW PROJECT CARD 0: Efficient Virtuoso (Diffusion Transformer) -->
                <div class="project-card">
                    <div class="project-visual">
                        <!-- This wrapper is now smarter -->
                        <div class="gif-comparison-grid-trigger single-image-trigger" 
                            data-project-id="efficient_virtuoso" 
                            data-title="Efficient Virtuoso: Goal Representation Ablation"
                            data-overall-caption="Qualitative comparison of goal representations in a challenging turning scenario. Click to expand.">
                            <!-- IMPORTANT: Remove the gif-comparison-grid wrapper for single images -->
                            <!-- <div class="gif-comparison-grid"> --> 
                                <div class="gif-item-single ">
                                    <!-- Add a specific class to the image -->
                                    <img src="assets\images\virtuoso\ablation_row4.png" alt="Qualitative comparison of goal representations in diffusion model" class="single-project-image">
                                    <p class="visual-caption">Our Sparse Route model (right) generates highly unbiased precise trajectories, outperforming other goal representations.</p>
                                </div>
                            <!-- </div> Removed div -->
                            <p class="visual-caption-overall">Qualitative comparison of goal representations in a challenging turning scenario. (Click to expand)</p>
                        </div>
                    </div>
                    <div class="project-info">
                        <h3>Efficient Virtuoso: Latent Diffusion Transformer for Trajectory Planning</h3>
                        <p>Developed a state-of-the-art conditional latent diffusion model for goal-conditioned trajectory planning, achieving a \textbf{minADE of 0.25} on Waymo Open Motion Dataset. Introduced novel normalization and provided key insights into optimal goal representation for AVs.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                            <li>Pioneered a two-stage normalization pipeline for stable latent diffusion training.</li>
                            <li>Designed a Transformer-based StateEncoder for rich scene context fusion.</li>
                            <li>Conducted rigorous ablation on goal representation, proving multi-step routes are critical for tactical precision.</li>
                            <li>Achieved state-of-the-art minADE of 0.25 on WOMD.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://arxiv.org/abs/2509.03658" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/DiffusionTrajectoryPlanner" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                </div>

                <!-- NEW PROJECT CARD 2: Mining the Long Tail -->
                <div class="project-card">
                    <div class="project-visual">
                        <div class="gif-comparison-grid-trigger" 
                            data-project-id="imit_opt" 
                            data-title="From Imitation to Optimization: Qualitative Comparison"
                            data-overall-caption="Qualitative comparison of Behavioral Cloning baselines vs. robust Offline RL (CQL) agent.">
                            <div class="gif-comparison-grid">
                                <div class="gif-item">
                                    <img src="assets/images/longtailgifs/video_1.gif" alt="Baseline CQL Agent failing a merge">
                                    <p class="visual-caption"><strong>Baseline CQL</strong>: Collision in merge scenario.</p>
                                </div>
                                <div class="gif-item">
                                    <img src="assets/images/longtailgifs/video_2.gif" width="300" alt="Heuristic Agent suboptimal merge">
                                    <p class="visual-caption"><strong>Heuristic-Weighted</strong>: Suboptimal, reactive merge.</p>
                                </div>
                                <div class="gif-item">
                                    <img src="assets/images/longtailgifs/video_3.gif" width="300" alt="Uncertainty Agent successful merge">
                                    <p class="visual-caption"><strong>Uncertainty-Weighted</strong>: Proactive, successful merge.</p>
                                </div>
                            </div>
                            <p class="visual-caption-overall">Qualitative comparison of data curation strategies in a challenging highway merge.</p>
                        </div>
                    </div>
                    <div class="project-info">
                        <h3>Mining the Long Tail: Data Curation for Robust Offline RL in AVs</h3>
                        <p>Systematically investigated six data curation strategies (heuristic, uncertainty, behavior-based) to tackle the long-tail problem in autonomous driving, achieving nearly a three-fold reduction in collision rate with uncertainty-based methods.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                            <li>Developed novel, data-driven criticality metrics (e.g., model disagreement via ensemble scouts) for non-uniform data sampling.</li>
                            <li>Designed specialized PyTorch `Dataset` implementations for timestep and scenario-level weighting.</li>
                            <li>Conducted large-scale comparative study demonstrating all curation methods significantly outperform uniform sampling.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://arxiv.org/abs/2508.18397" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/LongTailOfflineRL" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                </div>

                <!-- NEW PROJECT CARD 1: From Imitation to Optimization -->
                <div class="project-card">
                    <div class="project-visual">
                        <!-- Make the whole grid clickable -->
                        <div class="gif-comparison-grid-trigger" 
                            data-project-id="imit_opt" 
                            data-title="From Imitation to Optimization: Qualitative Comparison"
                            data-overall-caption="Qualitative comparison of Behavioral Cloning baselines vs. robust Offline RL (CQL) agent.">
                            <div class="gif-comparison-grid">
                                <div class="gif-item">
                                    <img src="assets/images/BCtoCQL/bcs_rollout.gif" alt="BC-S Agent failing to control">
                                    <p class="visual-caption"><strong>BC-S (MLP)</strong>: Fails due to complex interactions.</p>
                                </div>
                                <div class="gif-item">
                                    <img src="assets/images/BCtoCQL/bct_rollout.gif" alt="BC-T Agent circling failure">
                                    <p class="visual-caption"><strong>BC-T (Transformer)</strong>: Brittle, leads to "circling" failure.</p>
                                </div>
                                <div class="gif-item">
                                    <img src="assets/images/BCtoCQL/cql_rollout.gif" alt="CQL Agent robust control success">
                                    <p class="visual-caption"><strong>CQL (Offline RL)</strong>: Robust recovery, successfully navigates.</p>
                                </div>
                            </div>
                            <p class="visual-caption-overall">Qualitative comparison of Behavioral Cloning baselines vs. robust Offline RL (CQL) agent. (Click to expand)</p>
                        </div>
                    </div>
                    <div class="project-info">
                        <h3>From Imitation to Optimization: Offline Learning for Autonomous Driving</h3>
                        <p>Pioneered an end-to-end pipeline applying state-of-the-art Offline Reinforcement Learning (CQL) to the Waymo Open Motion Dataset, demonstrating significantly superior robustness over Behavioral Cloning baselines for long-horizon AV control.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                            <li>Engineered a robust, parallelized data processing pipeline for the Waymo Open Motion Dataset.</li>
                            <li>Conducted rigorous comparative study, demonstrating CQL's 3.2x higher success rate and 7.4x lower collision rate over Transformer-based BC.</li>
                            <li>Designed an effective multi-objective reward function for Offline RL training in autonomous driving.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://arxiv.org/abs/2508.07029" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/WaymoOfflineRL" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                </div>


                <div class="project-card">
                    <div class="project-visual">
                        <img src="assets/images/AIM.gif" alt="Animation of autonomous vehicles at an intersection">
                        <p class="visual-caption">MARL agents coordinating to cross an intersection safely.</p>
                    </div>
                    <div class="project-info">
                        <h3>Autonomous Intersection Management</h3>
                        <p>Designed and implemented a MARL system where autonomous vehicles learn to coordinate and safely cross intersections without traffic lights, significantly improving traffic flow.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                            <li>Designed the end-to-end MARL system architecture, including a novel LSTM-based state encoder.</li>
                            <li>Engineered the multi-objective reward function to balance efficiency and safety.</li>
                            <li>The final system reduced vehicle travel time by up to 59% in simulation.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://ieeexplore.ieee.org/document/9762548" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/Reinforcement-Autonomous-Intersection-Management--RAIM" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-visual">
                        <img src="assets/images/SustainDC.png" alt="SustainDC Architecture Diagram">
                         <p class="visual-caption">System architecture for the SustainDC benchmark.</p>
                    </div>
                    <div class="project-info">
                        <h3>SustainDC: A NeurIPS Benchmark</h3>
                        <p>Co-led the creation of an open-source, Gym-compatible benchmark for developing MARL controllers to optimize the energy and carbon footprint of data centers.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                            <li>Co-led the architectural design and open-source implementation.</li>
                            <li>Engineered the Python-based physics models for cooling and power.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/b6676756f8a935e208f394a1ba47f0bc-Abstract-Datasets_and_Benchmarks_Track.html" target="_blank">[NeurIPS Paper]</a>
                            <a href="https://github.com/HewlettPackard/dc-rl" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-visual">
                        <img src="assets/images/LfOD.png" alt="LfOD Framework Diagram">
                        <p class="visual-caption">Conceptual framework for Learning from Oracle Demonstrations.</p>
                    </div>
                    <div class="project-info">
                        <h3>Learning from Oracle Demonstrations (LfOD)</h3>
                        <p>Developed a novel Imitation Learning paradigm to accelerate DRL training by using a learned "Oracle" agent to provide corrective demonstrations to the primary agent.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                           <li>Engineered the core LfOD methodology from first principles.</li>
                           <li>Implemented the TD3fOD algorithm to integrate oracle advice.</li>
                            <li>Demonstrated a 5x speedup in training convergence on complex tasks.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://ieeexplore.ieee.org/abstract/document/9775674" target="_blank">[Paper]</a>
                        </div>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-visual">
                        <img src="assets/images/CFD.gif" alt="Animation showing the CNN prediction">
                        <p class="visual-caption">Animation showing the CNN prediction.</p>
                    </div>
                    <div class="project-info">
                        <h3>3D CNN Surrogate for Accelerating Physics Simulations</h3>
                        <p>Developed a 3D CNN (U-Net) to act as a fast proxy for computationally expensive CFD simulations to predict 3D heat distribution in data centers, achieving a >2800x inference speedup over the original simulator.</p>
                        <b>My Key Contributions:</b>
                        <ul>
                            <li>Evaluated 3D U-Net architectures for spatial heat prediction in data centers.</li>
                            <li>Engineered the data pipeline to process and voxelize raw CFD simulation data.</li>
                            <li>Used the surrogate model to optimize the workload placement using a genetic algorithm, reducing the maximum temperature by 7.7% and the energy consumption by 2.5%.</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://s3.us-east-1.amazonaws.com/climate-change-ai/papers/neurips2023/19/paper.pdf" target="_blank">[NeurIPS Workshop Paper]</a>
                        </div>
                    </div>
                </div>
            </section>

            <!-- ===== REVISED CORE TECHNICAL SKILLS SECTION ===== -->
            <section id="skills">
                <h2>Core Technical Skills</h2>
                <div class="skills-grid">
                    
                    <div class="skill-category">
                        <h3>Reinforcement & Decision Science</h3>
                        <ul>
                            <li><strong>Foundations:</strong> Sequential Decision-Making, MDPs, Multi-Objective Optimization, Credit Assignment</li>
                            <li><strong>Paradigms:</strong> Deep RL, Multi-Agent RL (MARL), Hierarchical RL (HRL), Imitation Learning (IL), Behavioral Cloning (BC), Learning from Demonstrations (LfD), <strong>Offline Reinforcement Learning (Offline RL)</strong></li>
                            <li><strong>Algorithms:</strong> Policy Gradient (PPO, A2C), Value-Based (SAC, TD3, Q-Learning, <strong>Conservative Q-Learning - CQL</strong>)</li>
                            <li><strong>Techniques:</strong> Model-Based RL, Off-Policy Learning, Exploration Strategies, <strong>Reward Function Design & Shaping</strong>, Policy Optimization, RLHF, <strong>Data-Centric RL (Curation, Sampling, Weighting)</strong></li>
                            <li><strong>Applications:</strong> Autonomous Driving Planning, Behavior Prediction, Robot Control, System Optimization</li>
                        </ul>
                    </div>
                    
                    <div class="skill-category">
                        <h3>Deep Learning & Generative AI</h3>
                        <ul>
                            <li><strong>LLM Agents:</strong> Agentic Frameworks, Tool Use, Planning, Fine-Tuning (PEFT, LoRA)</li>
                            <li><strong>Architectures:</strong> Transformers & Attention, CNNs (U-Net, V-Net), RNNs (LSTM)</li>
                            <li><strong>Generative Techniques:</strong> Surrogate Modeling, Data-Driven World Models, Diffusion Models (Conceptual)</li>
                            <li><strong>Frameworks:</strong> PyTorch, TensorFlow, Hugging Face Transformers</li>
                            <li><strong>Training Techniques:</strong> Transfer Learning, Fine-Tuning, Hyperparameter Optimization</li>
                            <li><strong>Evolutionary & Search Methods:</strong> Genetic Algorithms (for optimization), PSO, Bayesian Optimization</li>
                        </ul>
                    </div>
                    
                    <div class="skill-category">
                        <h3>High-Performance ML Engineering</h3>
                        <ul>
                            <li><strong>Distributed Systems:</strong> Large-Scale Training (Ray: RLlib, Tune), Parallel Computing, Distributed Data Processing</li>
                            <li><strong>Infrastructure:</strong> Scalable ML Pipelines, MLOps Concepts, HPC Environments, High-Throughput Data Loaders</li>
                            <li><strong>Performance:</strong> Model Evaluation & Benchmarking, Debugging Large ML Codebases, Performance Profiling</li>
                        </ul>
                    </div>
                    
                    <div class="skill-category">
                        <h3>Simulation & Embodied AI</h3>
                        <ul>
                            <li><strong>Environment Development:</strong> Digital Twins, World Models, (Gymnasium, PettingZoo), <strong>Waymax Simulator</strong></li>
                            <li><strong>Robotics Concepts:</strong> Motion & Behavioral Planning, Control Systems, Perception Pipeline, Trajectory Prediction, Safety & Robustness</li>
                            <li><strong>Tools & Data:</strong> Physics Simulators (SUMO, CARLA), <strong>Waymo Open Motion Dataset (WOMD)</strong>, Synthetic Data Generation, Real-World Data Integration, Large-Scale Datasets</li>
                        </ul>
                    </div>

                    <!-- NEW Proficiency Tiers Section -->
                    <div class="skill-category full-width proficiency-tiers">
                        <div class="tier">
                            <h4>Expert In</h4>
                            <p>Python, PyTorch, Ray (RLlib, Tune)</p>
                        </div>
                        <div class="tier">
                            <h4>Proficient With</h4>
                            <p>NumPy, Pandas, Scikit-learn, Stable Baselines3, Docker, Git, Linux, <strong>Waymo Open Motion Dataset (WOMD)</strong>, <strong>Waymax</strong>, C++ (Basic)</p>
                        </div>
                    </div>
                </div>
            </section>

            <section id="publications">
                <h2>Selected Publications</h2>
                <div class="publication-list">
                    <!-- NEW PUBLICATION 0 -->
                    <div class="publication-item">
                        <p class="pub-title">Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning</p>
                        <p class="pub-authors"><strong>A. Guillen-Perez</strong></p>
                        <p class="pub-venue"><em>arXiv preprint, August 2025</em></p>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2509.03658" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/DiffusionTrajectoryPlanner" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                    <!-- NEW PUBLICATION 1 -->
                    <div class="publication-item">
                        <p class="pub-title">Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning</p>
                        <p class="pub-authors"><strong>A. Guillen-Perez</strong></p>
                        <p class="pub-venue"><em>arXiv preprint, Aug 2025</em></p>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2508.18397" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/LongTailOfflineRL" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                    <!-- NEW PUBLICATION 2 -->
                    <div class="publication-item">
                        <p class="pub-title">From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving</p>
                        <p class="pub-authors"><strong>A. Guillen-Perez</strong></p>
                        <p class="pub-venue"><em>arXiv preprint, July 2025</em></p>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2508.07029" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/WaymoOfflineRL" target="_blank">[GitHub]</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <p class="pub-title">SustainDC: Benchmarking for Sustainable Data Center Control</p>
                        <p class="pub-authors">A. Naug*, <strong>A. Guillen-Perez</strong>*, R. Luna Gutierrez*, V. Gundecha, et al.</p>
                        <p class="pub-venue"><em>Advances in Neural Information Processing Systems (NeurIPS), 2024</em></p>
                        <div class="pub-links">
                            <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/b6676756f8a935e208f394a1ba47f0bc-Abstract-Datasets_and_Benchmarks_Track.html" target="_blank">[Paper]</a>
                            <a href="https://github.com/HewlettPackard/dc-rl" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                    <div class="publication-item">
                        <p class="pub-title">Learning From Oracle Demonstrations—A New Approach to Develop Autonomous Intersection Management...</p>
                        <p class="pub-authors"><strong>A. Guillen-Perez</strong>, M.D. Cano</p>
                        <p class="pub-venue"><em>IEEE Access, 2022</em></p>
                        <div class="pub-links">
                            <a href="https://ieeexplore.ieee.org/abstract/document/9775674" target="_blank">[Paper]</a>
                        </div>
                    </div>
                    <div class="publication-item">
                        <p class="pub-title">Multi-Agent Deep Reinforcement Learning to Manage Connected Autonomous Vehicles at Tomorrow's Intersections</p>
                        <p class="pub-authors"><strong>A. Guillen-Perez</strong>, M.D. Cano</p>
                        <p class="pub-venue"><em>IEEE Transactions on Vehicular Technology, 2022</em></p>
                        <div class="pub-links">
                            <a href="https://ieeexplore.ieee.org/document/9762548" target="_blank">[Paper]</a>
                            <a href="https://github.com/AntonioAlgaida/Reinforcement-Autonomous-Intersection-Management--RAIM" target="_blank">[GitHub]</a>
                        </div>
                    </div>
                    <div class="publication-item">
                        <p class="pub-title">N-CRITICS: Self-Refinement of Large Language Models with Ensemble of Critics</p>
                        <p class="pub-authors">Sajad Mousavi, Ricardo Luna Gutierrez, <strong>A. Guillen-Perez</strong>, et al.</p>
                        <p class="pub-venue"><em>NeurIPS 2023 Workshop on Robustness of Foundation Models</em></p>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2310.18679" target="_blank">[Paper]</a>
                        </div>
                    </div>
                </div>
                <p class="full-list-link">For a full list of publications, please visit my <a href="https://scholar.google.com/citations?user=BFS6jXwAAAAJ" target="_blank">Google Scholar profile</a>.</p>
            </section>
        </main>
        <footer>
            <p>© 2025 Antonio Guillen-Perez. Built with love using HTML and CSS.</p>
            <p>Last updated: Sept 2025</p>
            <p>Contact: antonio_algaida [at] hotmail [dot] com
        </footer>
    </div>


<!-- The Modal / Lightbox Structure -->
<div id="imageModal" class="modal">
    <div class="modal-content">
        <span class="close-button">&times;</span>
        <h3 id="modal-title"></h3>
        <!-- Container for grid of GIFs (for multi-item projects) -->
        <div id="modal-gif-grid" class="gif-comparison-grid modal-grid">
            <!-- GIFs will be dynamically loaded here -->
        </div>
        <!-- NEW Container for a single large image (for single-image projects) -->
        <div id="modal-single-image-container">
            <!-- Single image will be dynamically loaded here -->
            <img id="modal-single-image" src="" alt="Project Visual">
            <p id="modal-single-image-caption" class="visual-caption"></p>
        </div>
        <p id="modal-overall-caption" class="visual-caption-overall"></p>
    </div>
</div>

    
<!-- ADD THIS SCRIPT AT THE END OF YOUR HTML BODY -->
<script>
    const themeToggle = document.getElementById('theme-toggle');
    const body = document.body;

    // This function runs when the button is clicked
    themeToggle.addEventListener('click', () => {
        // Add or remove the .dark-mode class from the body
        body.classList.toggle('dark-mode');

        // Check if dark mode is now active and save the choice
        if (body.classList.contains('dark-mode')) {
            localStorage.setItem('theme', 'dark');
            themeToggle.textContent = '☀️'; // Change icon to sun
        } else {
            localStorage.setItem('theme', 'light');
            themeToggle.textContent = '🌙'; // Change icon to moon
        }
    });

    // This code runs when the page first loads
    // It checks if the user previously chose a theme
    document.addEventListener('DOMContentLoaded', () => {
        const savedTheme = localStorage.getItem('theme');
        if (savedTheme === 'dark') {
            body.classList.add('dark-mode');
            themeToggle.textContent = '☀️';
        } else {
            themeToggle.textContent = '🌙';
        }
    });
</script>

<script>
    // --- Lightbox / Modal Logic ---
    const modal = document.getElementById("imageModal");
    const closeButton = document.getElementsByClassName("close-button")[0];
    const gifTriggers = document.querySelectorAll(".gif-comparison-grid-trigger");
    const modalGifGrid = document.getElementById("modal-gif-grid");
    const modalSingleImageContainer = document.getElementById("modal-single-image-container");
    const modalSingleImage = document.getElementById("modal-single-image");
    const modalSingleImageCaption = document.getElementById("modal-single-image-caption");
    const modalTitle = document.getElementById("modal-title");
    const modalOverallCaption = document.getElementById("modal-overall-caption");

    gifTriggers.forEach(trigger => {
        trigger.addEventListener('click', function() {
            const projectId = this.dataset.projectId;
            const projectTitle = this.dataset.title;
            const projectOverallCaption = this.dataset.overallCaption;
            const isSingleImage = this.classList.contains('single-image-trigger'); // Check for the new class

            // Clear previous content
            modalGifGrid.innerHTML = '';
            modalSingleImage.src = '';
            modalSingleImageCaption.textContent = '';
            modalSingleImageContainer.classList.remove('active'); // Hide single image container by default
            modalGifGrid.classList.remove('active'); // Hide grid container by default


            // Populate modal title and overall caption
            modalTitle.textContent = projectTitle;
            modalOverallCaption.textContent = projectOverallCaption;

            if (isSingleImage) {
                // If it's a single image, grab its content
                const originalImage = this.querySelector('.single-project-image');
                const originalCaption = this.querySelector('.gif-item .visual-caption');

                if (originalImage) {
                    modalSingleImage.src = originalImage.src;
                    modalSingleImage.alt = originalImage.alt;
                    modalSingleImageContainer.classList.add('active'); // Show single image container
                    if (originalCaption) {
                         modalSingleImageCaption.textContent = originalCaption.textContent;
                    }
                }
            } else {
                // If it's a grid, load the grid content as before
                const originalGifItems = this.querySelectorAll('.gif-item');
                originalGifItems.forEach(item => {
                    const clonedItem = item.cloneNode(true); // Deep clone
                    modalGifGrid.appendChild(clonedItem);
                });
                modalGifGrid.classList.add('active'); // Show grid container
            }
            
            modal.classList.add('active'); // Show the modal
            document.body.style.overflow = 'hidden'; // Prevent scrolling the background
        });
    });

    // Close the modal when the close button is clicked
    closeButton.addEventListener('click', function() {
        modal.classList.remove('active');
        document.body.style.overflow = ''; // Re-enable scrolling
    });

    // Close the modal when clicking outside the modal content
    window.addEventListener('click', function(event) {
        if (event.target == modal) {
            modal.classList.remove('active');
            document.body.style.overflow = '';
        }
    });

    // Close the modal with the Escape key
    document.addEventListener('keydown', function(event) {
        if (event.key === "Escape" && modal.classList.contains('active')) {
            modal.classList.remove('active');
            document.body.style.overflow = '';
        }
    });
</script>

</body>
</html>
</body>
</html>